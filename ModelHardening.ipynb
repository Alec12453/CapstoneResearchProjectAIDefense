{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bb3bc20-b3bc-4c6b-a1f2-df521006749a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import models, layers, datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d58000d8-d729-470f-a80f-8439b410e944",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking suit directory: c:\\Users\\alec\\OneDrive - University of North Georgia\\FALL 2023\\Cyber capstone\\Experimentation\\SortedData\\train\\hearts\n",
      "Label index for hearts: 0\n",
      "Checking suit directory: c:\\Users\\alec\\OneDrive - University of North Georgia\\FALL 2023\\Cyber capstone\\Experimentation\\SortedData\\train\\diamonds\n",
      "Label index for diamonds: 1\n",
      "Checking suit directory: c:\\Users\\alec\\OneDrive - University of North Georgia\\FALL 2023\\Cyber capstone\\Experimentation\\SortedData\\train\\clubs\n",
      "Label index for clubs: 2\n",
      "Checking suit directory: c:\\Users\\alec\\OneDrive - University of North Georgia\\FALL 2023\\Cyber capstone\\Experimentation\\SortedData\\train\\spades\n",
      "Label index for spades: 3\n",
      "[3 3 2 0 1 0 3 0 2 2 1 3 0 3 1 1 3 2 3 2 0 0 2 0 3 1 0 0 2 0 0 1 3 1 3 1 2\n",
      " 1 3 3 3 0 0 0 2 3 3 3 0 0 3 0 3 0 1 0 0 3 2 0 1 3 1 1 1 3 3 3 3 2 1 0 1 0\n",
      " 2 3 2 3 0 1 3 0 1 3 3 3 1 2 1 3 3 3 0 3 1 3 2 2 0 1]\n",
      "Checking suit directory: c:\\Users\\alec\\OneDrive - University of North Georgia\\FALL 2023\\Cyber capstone\\Experimentation\\SortedData\\valid\\hearts\n",
      "Label index for hearts: 0\n",
      "Checking suit directory: c:\\Users\\alec\\OneDrive - University of North Georgia\\FALL 2023\\Cyber capstone\\Experimentation\\SortedData\\valid\\diamonds\n",
      "Label index for diamonds: 1\n",
      "Checking suit directory: c:\\Users\\alec\\OneDrive - University of North Georgia\\FALL 2023\\Cyber capstone\\Experimentation\\SortedData\\valid\\clubs\n",
      "Label index for clubs: 2\n",
      "Checking suit directory: c:\\Users\\alec\\OneDrive - University of North Georgia\\FALL 2023\\Cyber capstone\\Experimentation\\SortedData\\valid\\spades\n",
      "Label index for spades: 3\n",
      "[1 2 1 2 2 3 0 0 3 0 3 3 3 1 3 0 0 1 1 1 0 3 2 0 2 2 1 0 1 0 3 2 3 0 0 3 1\n",
      " 0 3 0 3 3 2 0 1 2 1 0 3 0 2 0 2 1 2 2 3 3 2 0 3 0 2 0 2 3 2 1 3 2 1 3 2 2\n",
      " 1 3 0 2 1 2 2 2 3 2 0 2 2 1 3 2 2 3 1 0 0 2 0 1 2 0]\n",
      "Checking suit directory: c:\\Users\\alec\\OneDrive - University of North Georgia\\FALL 2023\\Cyber capstone\\Experimentation\\SortedData\\test\\hearts\n",
      "Label index for hearts: 0\n",
      "Checking suit directory: c:\\Users\\alec\\OneDrive - University of North Georgia\\FALL 2023\\Cyber capstone\\Experimentation\\SortedData\\test\\diamonds\n",
      "Label index for diamonds: 1\n",
      "Checking suit directory: c:\\Users\\alec\\OneDrive - University of North Georgia\\FALL 2023\\Cyber capstone\\Experimentation\\SortedData\\test\\clubs\n",
      "Label index for clubs: 2\n",
      "Checking suit directory: c:\\Users\\alec\\OneDrive - University of North Georgia\\FALL 2023\\Cyber capstone\\Experimentation\\SortedData\\test\\spades\n",
      "Label index for spades: 3\n",
      "[1 2 2 1 2 2 0 3 1 0 3 0 2 2 2 1 2 1 2 2 0 1 2 2 0 3 0 2 1 3 0 0 0 0 0 1 3\n",
      " 0 3 3 3 1 2 2 3 0 2 2 1 3 3 3 3 1 3 1 0 1 3 1 1 1 0 2 0 0 3 0 1 1 3 3 1 2\n",
      " 1 0 1 1 0 3 0 2 0 0 0 2 0 3 1 3 0 1 1 0 1 0 1 0 2 1]\n",
      "(7509, 224, 224, 3) (7509,)\n",
      "(260, 224, 224, 3) (260,)\n",
      "(260, 224, 224, 3) (260,)\n",
      "{'hearts': 0, 'diamonds': 1, 'clubs': 2, 'spades': 3}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "def load_dataset(base_dir, target_size=(224, 224)):\n",
    "    images = []\n",
    "    labels = []\n",
    "    class_labels = {'hearts': 0, 'diamonds': 1, 'clubs': 2, 'spades': 3}\n",
    "    \n",
    "    # Navigate through each suit folder\n",
    "    for suit in class_labels.keys():\n",
    "        suit_dir = os.path.join(base_dir, suit)\n",
    "        print(f\"Checking suit directory: {suit_dir}\")  # Debug print\n",
    "        if os.path.isdir(suit_dir):\n",
    "            label_index = class_labels[suit]\n",
    "            print(f\"Label index for {suit}: {label_index}\")  # Debug print\n",
    "\n",
    "            # Navigate through each card folder within the suit folder\n",
    "            for card_folder in os.listdir(suit_dir):\n",
    "                card_folder_path = os.path.join(suit_dir, card_folder)\n",
    "                #print(f\"Checking card folder: {card_folder_path}\")  # Add this debug print\n",
    "                if os.path.isdir(card_folder_path):\n",
    "                    # Load each image from the card folder\n",
    "                    for image_file in os.listdir(card_folder_path):\n",
    "                        image_path = os.path.join(card_folder_path, image_file)\n",
    "                        image = load_img(image_path, target_size=target_size)\n",
    "                        #print(f\"Loading image: {image_path}\")  # Debug print\n",
    "                        image_array = img_to_array(image)\n",
    "                        images.append(image_array)\n",
    "                        labels.append(label_index)\n",
    "    \n",
    "    # After loading all images and labels, shuffle them\n",
    "    combined = list(zip(images, labels))\n",
    "    np.random.shuffle(combined)\n",
    "    images[:], labels[:] = zip(*combined)                    \n",
    "    \n",
    "    images = np.array(images, dtype='float32') / 255.0  # Normalize to [0, 1]\n",
    "    labels = np.array(labels, dtype='int32')\n",
    "    \n",
    "    # Print some of the labels to verify they are correct\n",
    "    print(labels[:100])\n",
    "    \n",
    "    return images, labels, class_labels\n",
    "\n",
    "# Directory Definitions\n",
    "base_dir = \"c:\\\\Users\\\\alec\\\\OneDrive - University of North Georgia\\\\FALL 2023\\\\Cyber capstone\\\\Experimentation\\\\SortedData\"\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'valid')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "\n",
    "# Usage\n",
    "train_images, train_labels, train_class_labels = load_dataset(train_dir)\n",
    "valid_images, valid_labels, valid_class_labels = load_dataset(validation_dir)\n",
    "test_images, test_labels, test_class_labels = load_dataset(test_dir)\n",
    "\n",
    "# Check shapes and class labels\n",
    "print(train_images.shape, train_labels.shape)\n",
    "print(valid_images.shape, valid_labels.shape)\n",
    "print(test_images.shape, test_labels.shape)\n",
    "print(train_class_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "650ffe15-9912-48af-a170-4799b9c7bbbe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Shuffle the training dataset\n",
    "train_indices = np.arange(train_images.shape[0])\n",
    "np.random.shuffle(train_indices)\n",
    "train_images = train_images[train_indices]\n",
    "train_labels = train_labels[train_indices]\n",
    "\n",
    "# Shuffle the validation dataset\n",
    "valid_indices = np.arange(valid_images.shape[0])\n",
    "np.random.shuffle(valid_indices)\n",
    "valid_images = valid_images[valid_indices]\n",
    "valid_labels = valid_labels[valid_indices]\n",
    "\n",
    "# Optionally, if you also want to shuffle the test dataset:\n",
    "test_indices = np.arange(test_images.shape[0])\n",
    "np.random.shuffle(test_indices)\n",
    "test_images = test_images[test_indices]\n",
    "test_labels = test_labels[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf384ce5-93c7-4965-8e89-eeb2b0a64e25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#/////IGNORE DATA AUGMENTATION///// \n",
    "#/////NOT NEEDED FOR TRAINING//////\n",
    "\n",
    "#from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "#from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# Data augmentation\n",
    "#data_gen = ImageDataGenerator(\n",
    "#    rotation_range=20,\n",
    "#    width_shift_range=0.2,\n",
    "#    height_shift_range=0.2,\n",
    "#    shear_range=0.2,\n",
    "#    zoom_range=0.2,\n",
    "#    horizontal_flip=True,\n",
    "#    fill_mode='nearest'\n",
    "#)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3544021-ffac-4f5c-b360-e3d1dd42cf18",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7509, 224, 224, 3) (7509,)\n",
      "(260, 224, 224, 3) (260,)\n",
      "(260, 224, 224, 3) (260,)\n"
     ]
    }
   ],
   "source": [
    "print(train_images.shape, train_labels.shape)\n",
    "print(valid_images.shape, valid_labels.shape)\n",
    "print(test_images.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "418560bf-a66b-4c21-bb84-e284d89e8609",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 2 2 2 1 1 3 1 2 3 0 3 0 0 2 2 2 2 0 0 0 0 0 0 2 3 1 2 1 0 3 3 0 0 1 3\n",
      " 1 3 3 1 1 3 0 1 3 3 0 3 3 0 0 1 2 3 1 2 3 2 2 1 1 1 0 1 1 2 3 0 2 0 3 0 2\n",
      " 0 3 1 0 1 1 2 2 0 3 0 2 2 2 3 2 3 1 1 3 2 2 0 1 2 0]\n"
     ]
    }
   ],
   "source": [
    "print(train_labels[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ced76760-6cf4-464a-b92f-df0a562219a0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " separable_conv2d (Separabl  (None, 224, 224, 64)      283       \n",
      " eConv2D)                                                        \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 112, 112, 64)      0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " separable_conv2d_1 (Separa  (None, 112, 112, 128)     8896      \n",
      " bleConv2D)                                                      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 56, 56, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " separable_conv2d_2 (Separa  (None, 56, 56, 256)       34176     \n",
      " bleConv2D)                                                      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 28, 28, 256)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 200704)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               51380480  \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4)                 1028      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 51424863 (196.17 MB)\n",
      "Trainable params: 51424863 (196.17 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SeparableConv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "input_shape = (224, 224, 3)\n",
    "\n",
    "model = Sequential([\n",
    "    # Increase the number of filters and add depthwise separable convolutions\n",
    "    SeparableConv2D(64, (3, 3), activation='relu', input_shape=input_shape, padding='same', depth_multiplier=1, kernel_regularizer=l2(0.001)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.1),\n",
    "\n",
    "    SeparableConv2D(128, (3, 3), activation='relu', padding='same', depth_multiplier=1, kernel_regularizer=l2(0.001)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.1),\n",
    "\n",
    "    SeparableConv2D(256, (3, 3), activation='relu', padding='same', depth_multiplier=1, kernel_regularizer=l2(0.001)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.25),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu', kernel_regularizer=l2(0.001)),  # Increased number of units in the dense layer\n",
    "    Dropout(0.25),\n",
    "    Dense(4, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c308d2dd-4755-4a42-bd12-a847c7d24b03",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "235/235 [==============================] - 297s 1s/step - loss: 1.2762 - accuracy: 0.3597 - val_loss: 1.0086 - val_accuracy: 0.4731\n",
      "Epoch 2/30\n",
      "235/235 [==============================] - 308s 1s/step - loss: 1.0158 - accuracy: 0.5058 - val_loss: 0.9302 - val_accuracy: 0.5654\n",
      "Epoch 3/30\n",
      "235/235 [==============================] - 309s 1s/step - loss: 0.9320 - accuracy: 0.5968 - val_loss: 0.7631 - val_accuracy: 0.7269\n",
      "Epoch 4/30\n",
      "235/235 [==============================] - 311s 1s/step - loss: 0.8397 - accuracy: 0.7217 - val_loss: 0.5494 - val_accuracy: 0.8692\n",
      "Epoch 5/30\n",
      "235/235 [==============================] - 306s 1s/step - loss: 0.7449 - accuracy: 0.7833 - val_loss: 0.5576 - val_accuracy: 0.8538\n",
      "Epoch 6/30\n",
      "235/235 [==============================] - 296s 1s/step - loss: 0.6778 - accuracy: 0.8104 - val_loss: 0.5423 - val_accuracy: 0.8769\n",
      "Epoch 7/30\n",
      "235/235 [==============================] - 296s 1s/step - loss: 0.6353 - accuracy: 0.8362 - val_loss: 0.5052 - val_accuracy: 0.8923\n",
      "Epoch 8/30\n",
      "235/235 [==============================] - 295s 1s/step - loss: 0.5973 - accuracy: 0.8482 - val_loss: 0.4767 - val_accuracy: 0.9038\n",
      "Epoch 9/30\n",
      "235/235 [==============================] - 295s 1s/step - loss: 0.5723 - accuracy: 0.8572 - val_loss: 0.5098 - val_accuracy: 0.8654\n",
      "Epoch 10/30\n",
      "235/235 [==============================] - 295s 1s/step - loss: 0.5606 - accuracy: 0.8623 - val_loss: 0.5051 - val_accuracy: 0.8885\n",
      "Epoch 11/30\n",
      "235/235 [==============================] - 295s 1s/step - loss: 0.5222 - accuracy: 0.8760 - val_loss: 0.4850 - val_accuracy: 0.8846\n",
      "Epoch 12/30\n",
      "235/235 [==============================] - 295s 1s/step - loss: 0.5213 - accuracy: 0.8840 - val_loss: 0.4980 - val_accuracy: 0.8962\n",
      "Epoch 13/30\n",
      "235/235 [==============================] - 295s 1s/step - loss: 0.5155 - accuracy: 0.8905 - val_loss: 0.4665 - val_accuracy: 0.9154\n",
      "Epoch 14/30\n",
      "235/235 [==============================] - 295s 1s/step - loss: 0.4861 - accuracy: 0.9042 - val_loss: 0.6050 - val_accuracy: 0.8462\n",
      "Epoch 15/30\n",
      "235/235 [==============================] - 295s 1s/step - loss: 0.4766 - accuracy: 0.9084 - val_loss: 0.5278 - val_accuracy: 0.8731\n",
      "Epoch 16/30\n",
      "235/235 [==============================] - 296s 1s/step - loss: 0.4723 - accuracy: 0.9146 - val_loss: 0.4764 - val_accuracy: 0.9192\n",
      "Epoch 17/30\n",
      "235/235 [==============================] - 295s 1s/step - loss: 0.4570 - accuracy: 0.9150 - val_loss: 0.5127 - val_accuracy: 0.8923\n",
      "Epoch 18/30\n",
      "235/235 [==============================] - 295s 1s/step - loss: 0.4574 - accuracy: 0.9232 - val_loss: 0.4780 - val_accuracy: 0.9038\n",
      "Epoch 19/30\n",
      "235/235 [==============================] - 297s 1s/step - loss: 0.4388 - accuracy: 0.9262 - val_loss: 0.5058 - val_accuracy: 0.9038\n",
      "Epoch 20/30\n",
      "235/235 [==============================] - 300s 1s/step - loss: 0.4365 - accuracy: 0.9265 - val_loss: 0.5024 - val_accuracy: 0.9000\n",
      "Epoch 21/30\n",
      "235/235 [==============================] - 295s 1s/step - loss: 0.4161 - accuracy: 0.9375 - val_loss: 0.4739 - val_accuracy: 0.9231\n",
      "Epoch 22/30\n",
      "235/235 [==============================] - 296s 1s/step - loss: 0.4057 - accuracy: 0.9403 - val_loss: 0.4847 - val_accuracy: 0.9115\n",
      "Epoch 23/30\n",
      "235/235 [==============================] - 295s 1s/step - loss: 0.4123 - accuracy: 0.9385 - val_loss: 0.4803 - val_accuracy: 0.9038\n",
      "Epoch 24/30\n",
      "235/235 [==============================] - 294s 1s/step - loss: 0.4164 - accuracy: 0.9387 - val_loss: 0.5463 - val_accuracy: 0.8962\n",
      "Epoch 25/30\n",
      "235/235 [==============================] - 295s 1s/step - loss: 0.4171 - accuracy: 0.9407 - val_loss: 0.4423 - val_accuracy: 0.9154\n",
      "Epoch 26/30\n",
      "235/235 [==============================] - 295s 1s/step - loss: 0.3982 - accuracy: 0.9461 - val_loss: 0.4370 - val_accuracy: 0.9154\n",
      "Epoch 27/30\n",
      "235/235 [==============================] - 295s 1s/step - loss: 0.3850 - accuracy: 0.9489 - val_loss: 0.4564 - val_accuracy: 0.9154\n",
      "Epoch 28/30\n",
      "235/235 [==============================] - 295s 1s/step - loss: 0.3702 - accuracy: 0.9538 - val_loss: 0.4641 - val_accuracy: 0.9192\n",
      "Epoch 29/30\n",
      "235/235 [==============================] - 295s 1s/step - loss: 0.3618 - accuracy: 0.9565 - val_loss: 0.4346 - val_accuracy: 0.9269\n",
      "Epoch 30/30\n",
      "235/235 [==============================] - 295s 1s/step - loss: 0.3551 - accuracy: 0.9587 - val_loss: 0.4604 - val_accuracy: 0.9154\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    #data_gen.flow(train_images, train_labels, batch_size=32),\n",
    "    train_images, train_labels,  # Use the original images and labels without augmentation\n",
    "    batch_size=32,\n",
    "    epochs=30,\n",
    "    validation_data=(valid_images, valid_labels)\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3bc70c58-8c51-405c-9e8d-11ddb068a810",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alec\\miniconda3\\envs\\jupyterenv\\Lib\\site-packages\\keras\\src\\engine\\training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('PlayingCardHardened.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c815f1-8ecf-4cae-9bab-338c526b2c1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
